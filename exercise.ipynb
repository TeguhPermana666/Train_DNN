{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python required >= 3.5 version\n",
    "import sys\n",
    "assert sys.version_info >=(3,5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "# TensorFlow ≥2.0 is required\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "assert tf.__version__ >= \"2.0\"\n",
    "\n",
    "%load_ext tensorboard\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "# make the output satable accros run\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "ROOT = \".\"\n",
    "chapter_id = \"DNN\"\n",
    "image_path = os.path.join(ROOT,\"images\",chapter_id)\n",
    "os.makedirs(image_path,exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id,tigh_layout=True,fig_extension=\"png\",resolution=300):\n",
    "    path = os.path.join(image_path,fig_id + \".\" + fig_extension)\n",
    "    print(\"save figure \",fig_id)\n",
    "    if tigh_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path,format=fig_extension,dpi=resolution)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Deep learning on CIFAR 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# a\n",
    "Exercise : Build a DNN with 20 hidden layers of 100 neurons each, use HE initialization and the elu activation function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "model_A = keras.models.Sequential()\n",
    "\n",
    "model_A.add(keras.layers.Flatten(input_shape=[32,32,3]))\n",
    "for _ in range(20):\n",
    "    model_A.add(keras.layers.Dense(100,activation=\"elu\",\n",
    "                                   kernel_initializer = 'he_normal'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# b\n",
    "\n",
    "Exercise : using nadam optimization and early stopping, train the network on the CIFAR 10 dataset, can load it with keras.datasets.cifar10.load_data(). The dataset is composed of 60k with 32 x 32 pixel color images (50k for train and 10k for testing) with 10 classes, so u ill need a softmax output layer with 10 neurons. Remember to search for the right learning rate each time you change the models arsitekture or hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets add output layer to the model\n",
    "model_A.add(keras.layers.Dense(10,activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets use a nadam optimizers with learning rate 5e-5, tried learning rates,1e-5,3e-5,1e-4,1e-3,3e-4, and 1e-2 and I compared their learning curves for 10 epochs each (using tensorboard callback, below) the learning rates 3e-5 and 1e-4 is prety good, so I tried 5e-5 which turned out to be slighly better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Nadam(learning_rate=5e-5,beta_1=0.9,beta_2=0.999)\n",
    "model_A.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "                optimizer=optimizer,\n",
    "                metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets load the CIFAR10 dataset. We also want to use early stopping, so we need a validation set. Lets use 5k images from 50k train images set as the validation set now the train images only 45k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170498071/170498071 [==============================] - 866s 5us/step\n"
     ]
    }
   ],
   "source": [
    "(X_train_full,y_train_full),(X_test,y_test) = keras.datasets.cifar10.load_data()\n",
    "# comprased train data\n",
    "X_train = X_train_full[5000:]\n",
    "y_train = y_train_full[5000:]\n",
    "# comprased validation data\n",
    "X_valid = X_train_full[:5000]\n",
    "y_valid = y_train_full[:5000]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=20)\n",
    "model_checkpoint_cb = keras.callbacks.ModelCheckpoint(\"cifar10.h5\",save_best_only=True)\n",
    "run_index = 1 # increment setiap melakukan train model\n",
    "run_logdir = os.path.join(os.curdir,\"my_cifar10_logs\",\"run{:03d}\".format(run_index))\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "callbacks=[early_stopping_cb, model_checkpoint_cb, tensorboard_cb]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 5160), started 0:29:38 ago. (Use '!kill 5160' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-306dcc1cb4707447\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-306dcc1cb4707447\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir =./my_cifar10_logs --port 6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.0856 - accuracy: 0.6095 - val_loss: 1.5794 - val_accuracy: 0.4756\n",
      "Epoch 2/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0734 - accuracy: 0.6136 - val_loss: 1.5863 - val_accuracy: 0.4832\n",
      "Epoch 3/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0681 - accuracy: 0.6159 - val_loss: 1.6167 - val_accuracy: 0.4814\n",
      "Epoch 4/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0610 - accuracy: 0.6186 - val_loss: 1.5918 - val_accuracy: 0.4840\n",
      "Epoch 5/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0568 - accuracy: 0.6200 - val_loss: 1.5856 - val_accuracy: 0.4764\n",
      "Epoch 6/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0567 - accuracy: 0.6197 - val_loss: 1.6048 - val_accuracy: 0.4652\n",
      "Epoch 7/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.0473 - accuracy: 0.6213 - val_loss: 1.6338 - val_accuracy: 0.4726\n",
      "Epoch 8/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0419 - accuracy: 0.6245 - val_loss: 1.6056 - val_accuracy: 0.4706\n",
      "Epoch 9/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0344 - accuracy: 0.6265 - val_loss: 1.6570 - val_accuracy: 0.4762\n",
      "Epoch 10/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0311 - accuracy: 0.6295 - val_loss: 1.6107 - val_accuracy: 0.4768\n",
      "Epoch 11/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0259 - accuracy: 0.6324 - val_loss: 1.6195 - val_accuracy: 0.4742\n",
      "Epoch 12/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0184 - accuracy: 0.6344 - val_loss: 1.6682 - val_accuracy: 0.4608\n",
      "Epoch 13/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0077 - accuracy: 0.6363 - val_loss: 1.6721 - val_accuracy: 0.4706\n",
      "Epoch 14/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0011 - accuracy: 0.6401 - val_loss: 1.6660 - val_accuracy: 0.4700\n",
      "Epoch 15/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0030 - accuracy: 0.6392 - val_loss: 1.6841 - val_accuracy: 0.4664\n",
      "Epoch 16/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9899 - accuracy: 0.6436 - val_loss: 1.6521 - val_accuracy: 0.4736\n",
      "Epoch 17/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9856 - accuracy: 0.6466 - val_loss: 1.6658 - val_accuracy: 0.4706\n",
      "Epoch 18/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9788 - accuracy: 0.6482 - val_loss: 1.7194 - val_accuracy: 0.4786\n",
      "Epoch 19/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.9718 - accuracy: 0.6496 - val_loss: 1.6765 - val_accuracy: 0.4714\n",
      "Epoch 20/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9636 - accuracy: 0.6526 - val_loss: 1.7169 - val_accuracy: 0.4766\n",
      "Epoch 21/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9655 - accuracy: 0.6548 - val_loss: 1.7060 - val_accuracy: 0.4770\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x23859267af0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_A.fit(X_train, y_train, epochs=100,\n",
    "          validation_data=(X_valid, y_valid),\n",
    "          callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 1s 2ms/step - loss: 1.5794 - accuracy: 0.4756\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.5793873071670532, 0.475600004196167]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_A = keras.models.load_model(\"cifar10.h5\")\n",
    "model_A.evaluate(X_valid,y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the model with the lowest validation loss gets about 47.6% accuracy on the validation set.it took 21 epochs to reach the lowest validation loss, now lets see if we can iprove performance using batch normalization"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.9 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4ec5c1472ff0ffb40d4bfde534367b3b628558da3aa61cb988263ac340cc3560"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
