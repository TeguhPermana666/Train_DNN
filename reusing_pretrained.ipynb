{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python required >= 3.5 version\n",
    "import sys\n",
    "assert sys.version_info >=(3,5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "# TensorFlow ≥2.0 is required\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "assert tf.__version__ >= \"2.0\"\n",
    "\n",
    "%load_ext tensorboard\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "# make the output satable accros run\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "ROOT = \".\"\n",
    "chapter_id = \"DNN\"\n",
    "image_path = os.path.join(ROOT,\"images\",chapter_id)\n",
    "os.makedirs(image_path,exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id,tigh_layout=True,fig_extension=\"png\",resolution=300):\n",
    "    path = os.path.join(image_path,fig_id + \".\" + fig_extension)\n",
    "    print(\"save figure \",fig_id)\n",
    "    if tigh_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path,format=fig_extension,dpi=resolution)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Clipping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "semua keras di optimizers clipnorm atau clipvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clip value can change the orientation gradient vector\n",
    "optimizer = keras.optimizers.SGD(learning_rate=1e-3,clipvalue=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if not want gradientn vector change the orientation value , we can use\n",
    "# clipnorm thats ill clip gradient if the l2 forn greater than theresold \n",
    "# which is pick\n",
    "optimizer = keras.optimizers.SGD(learning_rate=1e-3,clipnorm=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reusing pretrained layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's split the fashion MNIST training set in two:\n",
    "* `X_train_A`: all images of all items except for sandals and shirts (classes 5 and 6).\n",
    "* `X_train_B`: a much smaller training set of just the first 200 images of sandals or shirts.\n",
    "\n",
    "The validation set and the test set are also split this way, but without restricting the number of images.\n",
    "\n",
    "We will train a model on set A (classification task with 8 classes), and try to reuse it to tackle set B (binary classification). We hope to transfer a little bit of knowledge from task A to task B, since classes in set A (sneakers, ankle boots, coats, t-shirts, etc.) are somewhat similar to classes in set B (sandals and shirts). However, since we are using `Dense` layers, only patterns that occur at the same location can be reused (in contrast, convolutional layers will transfer much better, since learned patterns can be detected anywhere on the image, as we will see in the CNN chapter)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dataset fashion_mnist dataset\n",
    "(X_train_full,y_train_full),(X_test,y_test) = keras.datasets.fashion_mnist.load_data()\n",
    "# standarisasi train data\n",
    "X_train_full = X_train_full/255.0\n",
    "\n",
    "# split train data to train and validasi data\n",
    "X_valid,X_train = X_train_full[:5000], X_train_full[5000:]\n",
    "y_valid,y_train = y_train_full[:5000], y_train_full[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(X,y):\n",
    "    y_5_or_6 = (y==5) | (y==6) # sandls or shirts\n",
    "    y_A  = y[~y_5_or_6]\n",
    "    y_A[y_A >6]-=2 # class indices 7,8,9, should be moved to 5,6,7\n",
    "    y_B = (y[y_5_or_6] == 6).astype(np.float32)#binary classification task: is its shirt(class 6)?\n",
    "    return ((X[~y_5_or_6],y_A),\n",
    "           (X[y_5_or_6],y_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_A,y_train_A),(X_train_B,y_train_B) = split_dataset(X_train,y_train)\n",
    "(X_valid_A, y_valid_A), (X_valid_B, y_valid_B) = split_dataset(X_valid, y_valid)\n",
    "(X_test_A, y_test_A), (X_test_B, y_test_B) = split_dataset(X_test, y_test)\n",
    "X_train_B = X_train_B[:200]\n",
    "y_train_B = y_train_B[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43986, 28, 28)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 28, 28)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4014, 28, 28)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid_A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 28, 28)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_B.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 0, 5, 7, 7, 7, 4, 4, 3, 4, 0, 1, 6, 3, 4, 3, 2, 6, 5, 3, 4, 5,\n",
       "       1, 3, 4, 2, 0, 6, 7, 1], dtype=uint8)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_A[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 0., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
       "       0., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1.], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_B[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_B.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normal sequential model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arsitektur model A\n",
    "model_A = keras.models.Sequential()\n",
    "model_A.add(keras.layers.Flatten(input_shape=[28,28]))\n",
    "for n_hidden in (300,100,50,50,50):\n",
    "    model_A.add(keras.layers.Dense(n_hidden,activation=\"selu\"))\n",
    "model_A.add(keras.layers.Dense(8,activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "                optimizer=keras.optimizers.SGD(learning_rate=1e-3),\n",
    "                metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1375/1375 [==============================] - 4s 2ms/step - loss: 0.5926 - accuracy: 0.8103 - val_loss: 0.3895 - val_accuracy: 0.8665\n",
      "Epoch 2/20\n",
      "1375/1375 [==============================] - 2s 2ms/step - loss: 0.3523 - accuracy: 0.8786 - val_loss: 0.3289 - val_accuracy: 0.8824\n",
      "Epoch 3/20\n",
      "1375/1375 [==============================] - 2s 2ms/step - loss: 0.3170 - accuracy: 0.8895 - val_loss: 0.3013 - val_accuracy: 0.8991\n",
      "Epoch 4/20\n",
      "1375/1375 [==============================] - 2s 2ms/step - loss: 0.2972 - accuracy: 0.8975 - val_loss: 0.2893 - val_accuracy: 0.9021\n",
      "Epoch 5/20\n",
      "1375/1375 [==============================] - 3s 2ms/step - loss: 0.2834 - accuracy: 0.9021 - val_loss: 0.2775 - val_accuracy: 0.9071\n",
      "Epoch 6/20\n",
      "1375/1375 [==============================] - 2s 2ms/step - loss: 0.2729 - accuracy: 0.9062 - val_loss: 0.2730 - val_accuracy: 0.9073\n",
      "Epoch 7/20\n",
      "1375/1375 [==============================] - 2s 2ms/step - loss: 0.2641 - accuracy: 0.9092 - val_loss: 0.2719 - val_accuracy: 0.9088\n",
      "Epoch 8/20\n",
      "1375/1375 [==============================] - 2s 2ms/step - loss: 0.2572 - accuracy: 0.9127 - val_loss: 0.2589 - val_accuracy: 0.9136\n",
      "Epoch 9/20\n",
      "1375/1375 [==============================] - 2s 2ms/step - loss: 0.2518 - accuracy: 0.9138 - val_loss: 0.2563 - val_accuracy: 0.9143\n",
      "Epoch 10/20\n",
      "1375/1375 [==============================] - 2s 2ms/step - loss: 0.2469 - accuracy: 0.9153 - val_loss: 0.2541 - val_accuracy: 0.9163\n",
      "Epoch 11/20\n",
      "1375/1375 [==============================] - 3s 2ms/step - loss: 0.2422 - accuracy: 0.9175 - val_loss: 0.2494 - val_accuracy: 0.9158\n",
      "Epoch 12/20\n",
      "1375/1375 [==============================] - 2s 2ms/step - loss: 0.2382 - accuracy: 0.9189 - val_loss: 0.2508 - val_accuracy: 0.9131\n",
      "Epoch 13/20\n",
      "1375/1375 [==============================] - 2s 2ms/step - loss: 0.2350 - accuracy: 0.9199 - val_loss: 0.2444 - val_accuracy: 0.9155\n",
      "Epoch 14/20\n",
      "1375/1375 [==============================] - 2s 2ms/step - loss: 0.2315 - accuracy: 0.9212 - val_loss: 0.2414 - val_accuracy: 0.9175\n",
      "Epoch 15/20\n",
      "1375/1375 [==============================] - 2s 2ms/step - loss: 0.2287 - accuracy: 0.9212 - val_loss: 0.2448 - val_accuracy: 0.9188\n",
      "Epoch 16/20\n",
      "1375/1375 [==============================] - 2s 2ms/step - loss: 0.2254 - accuracy: 0.9224 - val_loss: 0.2384 - val_accuracy: 0.9195\n",
      "Epoch 17/20\n",
      "1375/1375 [==============================] - 2s 2ms/step - loss: 0.2230 - accuracy: 0.9233 - val_loss: 0.2407 - val_accuracy: 0.9180\n",
      "Epoch 18/20\n",
      "1375/1375 [==============================] - 2s 2ms/step - loss: 0.2201 - accuracy: 0.9246 - val_loss: 0.2426 - val_accuracy: 0.9153\n",
      "Epoch 19/20\n",
      "1375/1375 [==============================] - 2s 2ms/step - loss: 0.2178 - accuracy: 0.9254 - val_loss: 0.2329 - val_accuracy: 0.9203\n",
      "Epoch 20/20\n",
      "1375/1375 [==============================] - 2s 2ms/step - loss: 0.2156 - accuracy: 0.9260 - val_loss: 0.2330 - val_accuracy: 0.9210\n"
     ]
    }
   ],
   "source": [
    "history_model_A = model_A.fit(X_train_A,y_train_A,epochs=20,\n",
    "                              validation_data=[X_valid_A,y_valid_A])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A.save(\"my_model_A.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['deserialize',\n",
       " 'elu',\n",
       " 'exponential',\n",
       " 'gelu',\n",
       " 'get',\n",
       " 'hard_sigmoid',\n",
       " 'linear',\n",
       " 'relu',\n",
       " 'selu',\n",
       " 'serialize',\n",
       " 'sigmoid',\n",
       " 'softmax',\n",
       " 'softplus',\n",
       " 'softsign',\n",
       " 'swish',\n",
       " 'tanh']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in dir(keras.activations)if not i.startswith(\"_\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#arsitektur model_B\n",
    "model_B = keras.models.Sequential()\n",
    "model_B.add(keras.layers.Flatten(input_shape=[28,28]))\n",
    "for n_hidden in (300,100,50,50,50):\n",
    "    model_B.add(keras.layers.Dense(n_hidden,activation=\"selu\"))\n",
    "model_B.add(keras.layers.Dense(1,activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_B.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer=keras.optimizers.SGD(learning_rate=1e-2),\n",
    "                metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "7/7 [==============================] - 1s 28ms/step - loss: 0.5497 - accuracy: 0.7950 - val_loss: 0.2180 - val_accuracy: 0.9615\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.1635 - accuracy: 0.9850 - val_loss: 0.1405 - val_accuracy: 0.9736\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.1025 - accuracy: 0.9900 - val_loss: 0.1059 - val_accuracy: 0.9787\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0759 - accuracy: 0.9950 - val_loss: 0.0888 - val_accuracy: 0.9797\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0591 - accuracy: 0.9950 - val_loss: 0.0784 - val_accuracy: 0.9797\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0487 - accuracy: 0.9950 - val_loss: 0.0724 - val_accuracy: 0.9787\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0414 - accuracy: 0.9950 - val_loss: 0.0771 - val_accuracy: 0.9787\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0367 - accuracy: 0.9950 - val_loss: 0.0644 - val_accuracy: 0.9807\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0307 - accuracy: 0.9950 - val_loss: 0.0570 - val_accuracy: 0.9848\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0269 - accuracy: 0.9950 - val_loss: 0.0543 - val_accuracy: 0.9858\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0243 - accuracy: 0.9950 - val_loss: 0.0528 - val_accuracy: 0.9868\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0218 - accuracy: 0.9950 - val_loss: 0.0513 - val_accuracy: 0.9868\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0199 - accuracy: 0.9950 - val_loss: 0.0497 - val_accuracy: 0.9868\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0183 - accuracy: 0.9950 - val_loss: 0.0481 - val_accuracy: 0.9868\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0168 - accuracy: 0.9950 - val_loss: 0.0467 - val_accuracy: 0.9868\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0156 - accuracy: 0.9950 - val_loss: 0.0459 - val_accuracy: 0.9868\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0145 - accuracy: 0.9950 - val_loss: 0.0450 - val_accuracy: 0.9868\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0135 - accuracy: 0.9950 - val_loss: 0.0443 - val_accuracy: 0.9868\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0125 - accuracy: 0.9950 - val_loss: 0.0435 - val_accuracy: 0.9878\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0116 - accuracy: 0.9950 - val_loss: 0.0432 - val_accuracy: 0.9878\n"
     ]
    }
   ],
   "source": [
    "history_model_b=model_B.fit(X_train_B,y_train_B,epochs=20,\n",
    "                            validation_data=[X_valid_B,y_valid_B])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_1 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 300)               235500    \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 100)               30100     \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 50)                2550      \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 50)                2550      \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 275,801\n",
      "Trainable params: 275,801\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_B.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Used reused layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clone the baselien model a to model_B_on_A\n",
    "model_A = keras.models.load_model(\"my_model_A.h5\")\n",
    "model_A_clone = keras.models.clone_model(model_A)\n",
    "model_A_clone.set_weights(model_A.get_weights())\n",
    "# get the reused layers expect the output layers (-1)\n",
    "model_B_on_A = keras.models.Sequential(model_A_clone.layers[:-1])\n",
    "# create top hidden layers(output layers) for spesifik task\n",
    "model_B_on_A.add(keras.layers.Dense(1,activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "7/7 [==============================] - 0s 28ms/step - loss: 0.3634 - accuracy: 0.8750 - val_loss: 0.2634 - val_accuracy: 0.9320\n",
      "Epoch 2/4\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.2060 - accuracy: 0.9700 - val_loss: 0.1790 - val_accuracy: 0.9746\n",
      "Epoch 3/4\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.1417 - accuracy: 0.9850 - val_loss: 0.1371 - val_accuracy: 0.9817\n",
      "Epoch 4/4\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.1077 - accuracy: 0.9900 - val_loss: 0.1132 - val_accuracy: 0.9868\n"
     ]
    }
   ],
   "source": [
    "# freeze all reused layers\n",
    "for layer in model_B_on_A.layers[:-1]:\n",
    "    layer.trainable = False # expect the output layer isnt reused layer\n",
    "\n",
    "model_B_on_A.compile(loss=\"binary_crossentropy\",\n",
    "                     optimizer=keras.optimizers.SGD(learning_rate=1e-2),\n",
    "                     metrics=[\"accuracy\"])\n",
    "history_model_B_Freeze = model_B_on_A.fit(X_train_B,y_train_B,epochs=4,\n",
    "                                          validation_data = [X_valid_B,y_valid_B])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 784)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 300)               235500    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 100)               30100     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 50)                2550      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 50)                2550      \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 275,801\n",
      "Trainable params: 51\n",
      "Non-trainable params: 275,750\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_B_on_A.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0932 - accuracy: 0.9950 - val_loss: 0.1116 - val_accuracy: 0.9878\n",
      "Epoch 2/16\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0917 - accuracy: 0.9950 - val_loss: 0.1101 - val_accuracy: 0.9888\n",
      "Epoch 3/16\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0902 - accuracy: 1.0000 - val_loss: 0.1087 - val_accuracy: 0.9899\n",
      "Epoch 4/16\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0888 - accuracy: 1.0000 - val_loss: 0.1073 - val_accuracy: 0.9899\n",
      "Epoch 5/16\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0875 - accuracy: 1.0000 - val_loss: 0.1060 - val_accuracy: 0.9899\n",
      "Epoch 6/16\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0862 - accuracy: 1.0000 - val_loss: 0.1048 - val_accuracy: 0.9899\n",
      "Epoch 7/16\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0850 - accuracy: 1.0000 - val_loss: 0.1036 - val_accuracy: 0.9909\n",
      "Epoch 8/16\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0839 - accuracy: 1.0000 - val_loss: 0.1024 - val_accuracy: 0.9909\n",
      "Epoch 9/16\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0827 - accuracy: 1.0000 - val_loss: 0.1014 - val_accuracy: 0.9909\n",
      "Epoch 10/16\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0817 - accuracy: 1.0000 - val_loss: 0.1003 - val_accuracy: 0.9909\n",
      "Epoch 11/16\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0806 - accuracy: 1.0000 - val_loss: 0.0993 - val_accuracy: 0.9929\n",
      "Epoch 12/16\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0796 - accuracy: 1.0000 - val_loss: 0.0984 - val_accuracy: 0.9929\n",
      "Epoch 13/16\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0787 - accuracy: 1.0000 - val_loss: 0.0975 - val_accuracy: 0.9929\n",
      "Epoch 14/16\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0778 - accuracy: 1.0000 - val_loss: 0.0966 - val_accuracy: 0.9929\n",
      "Epoch 15/16\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0769 - accuracy: 1.0000 - val_loss: 0.0958 - val_accuracy: 0.9929\n",
      "Epoch 16/16\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0761 - accuracy: 1.0000 - val_loss: 0.0949 - val_accuracy: 0.9929\n"
     ]
    }
   ],
   "source": [
    "for layer in model_B_on_A.layers[:-1]:\n",
    "    layer.trainable = True\n",
    "model_B_on_A.compile(loss=\"binary_crossentropy\",\n",
    "                     optimizer=keras.optimizers.SGD(learning_rate=1e-4),#reduce learning rate, default 1e-2\n",
    "                     metrics=[\"accuracy\"])\n",
    "history_Model_B_Bnfreze = model_B_on_A.fit(X_train_B,y_train_B,epochs=16,\n",
    "                                           validation_data= [X_valid_B,y_valid_B]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 784)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 300)               235500    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 100)               30100     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 50)                2550      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 50)                2550      \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 275,801\n",
      "Trainable params: 275,801\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_B_on_A.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare the result model B baseline with model B reused layer model A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 1ms/step - loss: 2.1423 - accuracy: 0.8625\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.142326831817627, 0.862500011920929]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_B.evaluate(X_test_B,y_test_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 1ms/step - loss: 36.7105 - accuracy: 0.5005\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[36.710514068603516, 0.5005000233650208]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_B_on_A.evaluate(X_test_B,y_test_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5561277033985592"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(100-84.89) / (100-90.29)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! We got quite a bit of transfer: the error rate dropped by a factor of 1.18!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Faster Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "7/7 [==============================] - 2s 38ms/step - loss: 1.2136 - accuracy: 0.3200 - val_loss: 0.9280 - val_accuracy: 0.3367\n",
      "Epoch 2/16\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.8557 - accuracy: 0.5250 - val_loss: 0.6617 - val_accuracy: 0.6501\n",
      "Epoch 3/16\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.5108 - accuracy: 0.7500 - val_loss: 0.5346 - val_accuracy: 0.7089\n",
      "Epoch 4/16\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.3104 - accuracy: 0.8550 - val_loss: 0.4685 - val_accuracy: 0.7373\n",
      "Epoch 5/16\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.2369 - accuracy: 0.9200 - val_loss: 0.4168 - val_accuracy: 0.7748\n",
      "Epoch 6/16\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.1907 - accuracy: 0.9450 - val_loss: 0.3664 - val_accuracy: 0.8093\n",
      "Epoch 7/16\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.1904 - accuracy: 0.9450 - val_loss: 0.3225 - val_accuracy: 0.8469\n",
      "Epoch 8/16\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.1506 - accuracy: 0.9700 - val_loss: 0.2848 - val_accuracy: 0.8783\n",
      "Epoch 9/16\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.1409 - accuracy: 0.9800 - val_loss: 0.2557 - val_accuracy: 0.9067\n",
      "Epoch 10/16\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.1285 - accuracy: 0.9850 - val_loss: 0.2277 - val_accuracy: 0.9229\n",
      "Epoch 11/16\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.1314 - accuracy: 0.9750 - val_loss: 0.2081 - val_accuracy: 0.9341\n",
      "Epoch 12/16\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.1289 - accuracy: 0.9750 - val_loss: 0.1919 - val_accuracy: 0.9452\n",
      "Epoch 13/16\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.1072 - accuracy: 0.9850 - val_loss: 0.1800 - val_accuracy: 0.9533\n",
      "Epoch 14/16\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.1066 - accuracy: 0.9850 - val_loss: 0.1691 - val_accuracy: 0.9594\n",
      "Epoch 15/16\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.1522 - accuracy: 0.9450 - val_loss: 0.1604 - val_accuracy: 0.9645\n",
      "Epoch 16/16\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.1032 - accuracy: 0.9900 - val_loss: 0.1512 - val_accuracy: 0.9665\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_B = keras.models.Sequential()\n",
    "model_B.add(keras.layers.Flatten(input_shape=[28,28]))\n",
    "for n_hidden in (300,100,50,50,50):\n",
    "    model_B.add(keras.layers.Dense(n_hidden,activation=\"selu\"))\n",
    "    model_B.add(keras.layers.BatchNormalization())\n",
    "model_B.add(keras.layers.Dense(1,activation=\"sigmoid\"))\n",
    "\n",
    "model_B.compile(loss=\"binary_crossentropy\",\n",
    "                     optimizer=keras.optimizers.SGD(learning_rate=1e-4,momentum=0.9),#reduce learning rate, default 1e-2\n",
    "                     metrics=[\"accuracy\"])\n",
    "history_Model_B_momentum = model_B.fit(X_train_B,y_train_B,epochs=16,\n",
    "                                           validation_data= [X_valid_B,y_valid_B]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Momentum optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.SGD(learning_rate=1e-3,momentum=0.9)\n",
    "# 0 -> high friction, 1-> no fritction\n",
    "# semakin kecil friction maka semakin besar moemntum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Momentum Optimzation based on NAG (nestrov accrelation gradient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"images\\DNN\\NAG.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image(url=r\"images\\DNN\\NAG.png\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pada saat momentum push weight kedalam lembah maka \n",
    "\n",
    "v1 (perubahan 1) => menjauhi lmbah\n",
    "\n",
    "v2 (perubahan 2) => mendorong kembali kebwah lembah\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.SGD(learning_rate=1e-3, momentum=0.9,nesterov=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Ada Grad "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"images\\DNN\\Ada grad.PNG\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=r\"images\\DNN\\Ada grad.PNG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Menghancurkan (decays learning rate) sehingga akan lebih cepat pada proses lereng curam namun bahaya seringkali terjadi pemberhentian lebih awal sehingga hanya mencapai local optimum, tidak di anjurkan untuk deep neural network (only can be use on simple task (linear regression))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adagrad(learning_rate=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. RMS Prop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.RMSprop(learning_rate=1e-3,rho=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. ADAM Optimization\n",
    "combine momentum and RMSprop omtization\n",
    "decaying average by past gradient and exponential(squared) gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.set_epsilon(1e-7)\n",
    "optimizer = keras.optimizers.Adam(learning_rate=1e-3,beta_1=0.9,beta_2=0.999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.1. ADAMAX optimzation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer= keras.optimizers.Adamax(learning_rate=1e-3,beta_1=0.9,beta_2=0.999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.2 NADAM Optimzation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer= keras.optimizers.Nadam(learning_rate=1e-3,beta_1=0.9,beta_2=0.999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"images\\DNN\\table_optimzation.PNG\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=r\"images\\DNN\\table_optimzation.PNG\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.9 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4ec5c1472ff0ffb40d4bfde534367b3b628558da3aa61cb988263ac340cc3560"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
